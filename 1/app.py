import streamlit as st
import joblib
import numpy as np
import re
import string
import pandas as pd
import altair as alt

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer


# ==============================
# 0. –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–µ–π (–∏–∑ –Ω–æ—É—Ç–±—É–∫–∞)
# ==============================

MODEL_METRICS = {
    "Logistic Regression": {
        "accuracy": 0.794,
        "precision": 0.794,
        "recall": 0.794,
        "f1": 0.794,
    },
    "Linear SVM (calibrated)": {
        "accuracy": 0.790,
        "precision": 0.791,
        "recall": 0.790,
        "f1": 0.790,
    },
    "Multinomial Naive Bayes": {
        "accuracy": 0.767,
        "precision": 0.767,
        "recall": 0.767,
        "f1": 0.767,
    },
}
# –ö–æ—Ä–æ—Ç–∫–∏–µ –∏–º–µ–Ω–∞ –º–æ–¥–µ–ª–µ–π ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
SHORT_NAMES = {
    "Logistic Regression": "Logistic Regression",
    "Linear SVM (calibrated)": "Linear SVM",
    "Multinomial Naive Bayes": "Naive Bayes",
}



# ==============================
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
# ==============================

@st.cache_resource
def load_models():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—ã–π TF-IDF –∏ —Ç—Ä–∏ –º–æ–¥–µ–ª–∏:
    - Logistic Regression
    - Linear SVM (–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π)
    - Multinomial Naive Bayes

    –î–æ–±–∞–≤–ª–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫: –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å
    —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ, –∞ –Ω–µ –º–æ–ª—á–∞ –ø–∞–¥–∞—Ç—å.
    """
    try:
        tfidf = joblib.load("artifacts/tfidf_vectorizer.joblib")

        models = {
            "Logistic Regression": joblib.load("artifacts/logreg_best.joblib"),
            "Linear SVM (calibrated)": joblib.load("artifacts/linear_svc_best.joblib"),
            "Multinomial Naive Bayes": joblib.load("artifacts/mnb_best.joblib"),
        }

    except FileNotFoundError as e:
        st.error(
            "‚ùå **–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –≤ –ø–∞–ø–∫–µ `artifacts/`.**\n"
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã **–æ–±—É—á–∏–ª–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã** (joblib-—Ñ–∞–π–ª—ã)."
        )
        raise e

    return tfidf, models


# ==============================
# 2. –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
# ==============================

@st.cache_resource
def get_text_tools():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å—ë –Ω—É–∂–Ω–æ–µ –¥–ª—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞:
    —Å—Ç–æ–ø-—Å–ª–æ–≤–∞, —Å—Ç–µ–º–º–µ—Ä –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (–∫–∞–∫ –≤ –Ω–æ—É—Ç–±—É–∫–µ).
    """
    nltk.download("stopwords", quiet=True)
    stop_words = set(stopwords.words("english"))
    ps = PorterStemmer()

    # –¢–æ—Ç –∂–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, —á—Ç–æ –∏ –≤ –Ω–æ—É—Ç–±—É–∫–µ
    re_tok = re.compile(f'([{string.punctuation}‚Äú‚Äù¬® ¬´¬ª¬Æ¬¥¬∑¬∫¬Ω¬æ¬ø¬°¬ß¬£‚Ç§‚Äò‚Äô])')

    def tokenize(s: str):
        return re_tok.sub(r" \1 ", s).split()

    return stop_words, ps, tokenize


# ==============================
# 3. –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
# ==============================

def preprocess_text(text: str, stop_words, ps, tokenize) -> str:
    """
    –ü–æ–ª–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥:
    - —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    - —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤
    - —Å—Ç–µ–º–º–∏–Ω–≥
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É.
    """
    tokens = [w for w in tokenize(text) if w.lower() not in stop_words]
    tokens = [ps.stem(w) for w in tokens]
    return " ".join(tokens)


def predict_sentiment(text: str, tfidf, model, stop_words, ps, tokenize):
    """
    –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (prob_pos, label, text_clean), –≥–¥–µ:
    - prob_pos    ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
    - label       ‚Äî 1 (positive) –∏–ª–∏ 0 (negative)
    - text_clean  ‚Äî —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
    """
    text_clean = preprocess_text(text, stop_words, ps, tokenize)
    X_vec = tfidf.transform([text_clean])

    prob_pos = model.predict_proba(X_vec)[0, 1]
    label = int(prob_pos >= 0.5)

    return prob_pos, label, text_clean


# ==============================
# 4. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit
# ==============================

def main():
    st.set_page_config(
        page_title="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é",
        page_icon="üí¨",
        layout="wide",
    )

    # ----- –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ -----
    st.title("üí¨ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é")

    st.markdown(
        """
        –≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤ (–æ—Ç–∑—ã–≤—ã, —Ç–≤–∏—Ç—ã, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏) –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.

        –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –Ω–∞ –±–æ–ª—å—à–∏—Ö –∫–æ—Ä–ø—É—Å–∞—Ö –æ—Ç–∑—ã–≤–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TF-IDF-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        –ù–∏–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∫–∞–∫ –æ–Ω–∞ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–∞—à —Ç–µ–∫—Å—Ç.
        """
    )
    st.divider()
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤
    if "history" not in st.session_state:
        st.session_state["history"] = []


    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
    tfidf, models = load_models()
    stop_words, ps, tokenize = get_text_tools()

    # ================= SIDEBAR: –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ =================
    st.sidebar.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    model_name = st.sidebar.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å",
        list(models.keys()),
        index=0,
    )
    current_model = models[model_name]

    metrics = MODEL_METRICS.get(model_name)
    if metrics:
        st.sidebar.markdown("### üìä –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏")
        st.sidebar.metric("Accuracy", f"{metrics['accuracy']:.3f}")
        st.sidebar.metric("F1 (weighted)", f"{metrics['f1']:.3f}")
        st.sidebar.caption("–ú–µ—Ç—Ä–∏–∫–∏ –≤–∑—è—Ç—ã –∏–∑ –æ—Ñ—Ñ–ª–∞–π–Ω-–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.")
    st.sidebar.markdown("---")
    st.sidebar.caption("–ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –Ω–∞ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö.")

    # ================= –í–∫–ª–∞–¥–∫–∏ =================
    tab_single, tab_compare, tab_train = st.tabs(
        ["üîç –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞", "üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π", "üìö –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"]
    )

    # ---------- –í–∫–ª–∞–¥–∫–∞ 1: –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ ----------
    with tab_single:
        st.subheader("1. –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)")

        # —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –ø—Ä–∏–º–µ—Ä–æ–≤/–æ—á–∏—Å—Ç–∫–∏
        if "input_text" not in st.session_state:
            st.session_state["input_text"] = ""

        # –∫–Ω–æ–ø–∫–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
        col_ex1, col_ex2, col_ex3 = st.columns(3)
        with col_ex1:
            if st.button("üëç –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π –ø—Ä–∏–º–µ—Ä"):
                st.session_state["input_text"] = (
                    "This movie was really good, I enjoyed every minute of it!"
                )
        with col_ex2:
            if st.button("üëé –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–∏–º–µ—Ä"):
                st.session_state["input_text"] = (
                    "This movie was terrible and boring, I would not recommend it."
                )
        with col_ex3:
            if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å"):
                st.session_state["input_text"] = ""

        user_text = st.text_area(
            "–¢–µ–∫—Å—Ç",
            height=180,
            placeholder="For example: This movie was surprisingly good...",
            value=st.session_state["input_text"],
        )

        # –º–∞–ª–µ–Ω—å–∫–∏–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
        st.caption(f"–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(user_text.split())} —Å–ª–æ–≤")

        st.subheader("2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è")
        st.caption(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: **{model_name}**")

        if st.button("üîç –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ"):
            if not user_text.strip():
                st.warning("–°–Ω–∞—á–∞–ª–∞ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç.")
            else:
                prob_pos, label, text_clean = predict_sentiment(
                    user_text, tfidf, current_model, stop_words, ps, tokenize
                )

                sentiment = "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π" if label == 1 else "–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π"
                prob_neg = 1.0 - prob_pos

                # --- –∫–∞—Ä—Ç–æ—á–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ---
                col_res_left, col_res_right = st.columns([2, 1])
                with col_res_left:
                    st.success(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: **{sentiment}**")
                    st.write(
                        f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞: "
                        f"`{prob_pos:.3f}`, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–≥–æ: `{prob_neg:.3f}`"
                    )
                with col_res_right:
                    st.metric("p(positive)", f"{prob_pos:.3f}")
                    st.metric("p(negative)", f"{prob_neg:.3f}")

                # --- –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ ---
                if prob_pos > 0.9 or prob_pos < 0.1:
                    st.info("–ú–æ–¥–µ–ª—å –¥–æ–≤–æ–ª—å–Ω–æ —É–≤–µ—Ä–µ–Ω–∞ –≤ —Å–≤–æ—ë–º –æ—Ç–≤–µ—Ç–µ.")
                else:
                    st.info(
                        "–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–≤–µ—Ä–µ–Ω–∞ ‚Äî —Ç–µ–∫—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º "
                        "–∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–º–µ—à–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏."
                    )

                # --- –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫ —Ç–µ–∫—Å—Ç –∏–∑–º–µ–Ω–∏–ª—Å—è –ø–æ—Å–ª–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ ---
                with st.expander("üîß –ü–æ—à–∞–≥–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"):
                    st.markdown("**–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:**")
                    st.write(user_text)

                    st.markdown("**–ü–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å—Ç–æ–ø-—Å–ª–æ–≤–∞, —Å—Ç–µ–º–º–∏–Ω–≥):**")
                    st.write(text_clean)

                # ---------- —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é ----------
                short_text = user_text.strip().replace("\n", " ")
                if len(short_text) > 80:
                    short_text = short_text[:77] + "..."

                st.session_state["history"].insert(
                    0,
                    {
                        "text": user_text,
                        "preprocessed": text_clean,
                        "short_text": short_text,
                        "model": model_name,
                        "sentiment": sentiment,
                        "prob_pos": prob_pos,
                        "prob_neg": prob_neg,
                    },
                )
                # —Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∑–∞–ø–∏—Å–µ–π
                st.session_state["history"] = st.session_state["history"][:5]

                # ---------- –≤—ã–≤–æ–¥–∏–º –∏—Å—Ç–æ—Ä–∏—é + –∫–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ ----------
                if st.session_state["history"]:
                    st.markdown("#### –ò—Å—Ç–æ—Ä–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")

                    # –∫–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
                    if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é", key="clear_history"):
                        st.session_state["history"] = []
                    else:
                        for i, item in enumerate(st.session_state["history"], start=1):
                            with st.expander(
                                f"{i}. {item['sentiment']} "
                                f"(*{item['model']}*, p_pos={item['prob_pos']:.3f}) ‚Äî "
                                f"¬´{item['short_text']}¬ª"
                            ):
                                st.markdown("**–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:**")
                                st.write(item["text"])

                                st.markdown("**–ü–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:**")
                                st.write(item["preprocessed"])



    # ---------- –í–∫–ª–∞–¥–∫–∞ 2: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ----------
    with tab_compare:
        st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º")

        df_metrics = pd.DataFrame(MODEL_METRICS).T  # index = –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        df_metrics = df_metrics[["accuracy", "precision", "recall", "f1"]].round(3)
        st.dataframe(df_metrics, use_container_width=True)

        st.markdown("#### F1-score –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")

        # –°—Ç—Ä–æ–∏–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–º–µ–Ω–∞
        df_plot = df_metrics.reset_index().rename(columns={"index": "model"})
        df_plot["model_short"] = df_plot["model"].map(SHORT_NAMES)

        chart = (
            alt.Chart(df_plot)
            .mark_bar()
            .encode(
                # –ø–æ –æ—Å–∏ X –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è, –≤ tooltip ‚Äî –ø–æ–ª–Ω–æ–µ
                x=alt.X(
                    "model_short:N",
                    sort=None,
                    axis=alt.Axis(title="–ú–æ–¥–µ–ª—å", labelAngle=0),
                ),
                y=alt.Y("f1:Q", title="F1-score"),
                tooltip=["model", "f1"],
            )
            .properties(height=280)
        )

        st.altair_chart(chart, use_container_width=True)

        st.markdown("---")
        st.subheader("–ö—Ä–∞—Ç–∫–æ –æ –º–æ–¥–µ–ª—è—Ö")

        st.markdown(
            """
            - **Logistic Regression** ‚Äî –ª–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å, —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ TF-IDF-–ø—Ä–∏–∑–Ω–∞–∫–∞—Ö,
              –¥–∞—ë—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–µ –≤–µ—Å–∞ –¥–ª—è —Å–ª–æ–≤.
            - **Linear SVM (calibrated)** ‚Äî –æ–ø–æ—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã —Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π
              –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (CalibratedClassifierCV, –º–µ—Ç–æ–¥ *sigmoid*).
            - **Multinomial Naive Bayes** ‚Äî –ø—Ä–æ—Å—Ç–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤,
              —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ —Å–∏–ª—å–Ω–∞—è –±–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è.
            """
        )

        with st.expander("–ß—Ç–æ —Ç–∞–∫–æ–µ TF-IDF?"):
            st.write(
                """
                TF-IDF (Term Frequency ‚Äì Inverse Document Frequency) ‚Äî
                —Å–ø–æ—Å–æ–± –æ—Ü–µ–Ω–∏—Ç—å ¬´–≤–∞–∂–Ω–æ—Å—Ç—å¬ª —Å–ª–æ–≤–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤—Å–µ–≥–æ –∫–æ—Ä–ø—É—Å–∞.
                –ß–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è –≤–æ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —Å–ª–æ–≤–∞ (—Ç–∏–ø–∞ *the, and, of*)
                –ø–æ–ª—É—á–∞—é—Ç –º–∞–ª—ã–π –≤–µ—Å, –∞ —Å–ª–æ–≤–∞, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –∏–º–µ–Ω–Ω–æ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ ‚Äî
                –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π.
                """
            )

        with st.expander("–ß—Ç–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –≤ —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ?"):
            st.markdown(
                """
                1. –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã (—Å–ª–æ–≤–∞ –∏ –∑–Ω–∞–∫–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏).  
                2. –£–¥–∞–ª—è–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ (*the, and, of, ...*).  
                3. –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–µ–º–º–∏–Ω–≥ (PorterStemmer), –ø—Ä–∏–≤–æ–¥—è —Å–ª–æ–≤–∞ –∫ –æ—Å–Ω–æ–≤–µ  
                   (*liked ‚Üí like, movies ‚Üí movi*).  
                4. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç –≤ TF-IDF –≤–µ–∫—Ç–æ—Ä –∏ –ø–æ–¥–∞—ë–º –≤ –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å.
                """
            )

    # ---------- –í–∫–ª–∞–¥–∫–∞ 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ----------
    with tab_train:
        st.subheader("–û–±—â–∞—è —Å—Ö–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π")

        st.markdown(
            """
            **1. –î–∞–Ω–Ω—ã–µ**

            - –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞—Ç–∞—Å–µ—Ç—ã –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ —Å –º–µ—Ç–∫–∞–º–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (0 ‚Äî –Ω–µ–≥–∞—Ç–∏–≤, 1 ‚Äî –ø–æ–∑–∏—Ç–∏–≤).
            - –î–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–µ–Ω—ã: —É–±—Ä–∞–Ω—ã HTML-—Ç–µ–≥–∏, —Å—Å—ã–ª–∫–∏, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã, –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Ç.–¥.

            **2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞**

            - –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É  
            - —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π  
            - —É–¥–∞–ª–µ–Ω–∏–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å—Ç–æ–ø-—Å–ª–æ–≤ (NLTK `stopwords`)  
            - —Å—Ç–µ–º–º–∏–Ω–≥ (PorterStemmer)  
            - –æ–±—Ä–∞—Ç–Ω–æ–µ —Å–∫–ª–µ–∏–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å—Ç—Ä–æ–∫—É  

            **3. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (TF-IDF)**

            - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `TfidfVectorizer` –∏–∑ `scikit-learn`.  
            - –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π/–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–æ—Ç–µ —Ç–µ—Ä–º–æ–≤, `ngram_range=(1, 5)`.  
            - –ù–∞ –≤—ã—Ö–æ–¥–µ ‚Äî —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–µ–π.

            **4. –ú–æ–¥–µ–ª–∏**

            - **Logistic Regression** (`LogisticRegression`)  
              - –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å–µ—Ç–∫–µ (C, penalty, solver, class_weight) —á–µ—Ä–µ–∑ `GridSearchCV`.  
            - **Linear SVM (calibrated)**  
              - –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å `LinearSVC`,  
              - –æ–±—ë—Ä—Ç–∫–∞ `CalibratedClassifierCV(method="sigmoid")` –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π,  
              - –≤–æ–∑–º–æ–∂–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—É `C`.  
            - **Multinomial Naive Bayes** (`MultinomialNB`)  
              - –∞–ª—å—Ñ–∞-–ø–∞—Ä–∞–º–µ—Ç—Ä —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –ø–æ–¥–æ–±—Ä–∞–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ.

            **5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞**

            - –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train/test.  
            - –ú–µ—Ç—Ä–∏–∫–∏: *accuracy, precision, recall, F1* (–≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ).  
            - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å—Ç—Ä–æ–∏–ª–∏—Å—å –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –∏ ROC-–∫—Ä–∏–≤—ã–µ (–≤ –Ω–æ—É—Ç–±—É–∫–µ).

            **6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤**

            - –û–±—É—á–µ–Ω–Ω—ã–π TF-IDF-–≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –∏ –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é `joblib.dump(...)` –≤ –ø–∞–ø–∫—É `artifacts/`.  
            - –í —ç—Ç–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –æ–Ω–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ–Ω–ª–∞–π–Ω-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
            """
        )



if __name__ == "__main__":
    main()

